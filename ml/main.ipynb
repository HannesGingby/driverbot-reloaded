{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18346cfb",
   "metadata": {},
   "source": [
    "### **Training, save with float32**\n",
    "\n",
    "Do not use operations not supported by k210, https://github.com/kendryte/nncase/blob/v0.2.0-beta4/docs/tflite_ops.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a747b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 241 images belonging to 7 classes.\n",
      "Found 58 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23hangin\\AppData\\Local\\Temp\\ipykernel_30744\\3335215770.py:48: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base = MobileNetV2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23hangin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3149 - loss: 1.9324\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65517, saving model to best_head_v3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 227ms/step - accuracy: 0.3225 - loss: 1.9108 - val_accuracy: 0.6552 - val_loss: 0.8445 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7299 - loss: 0.8500\n",
      "Epoch 2: val_accuracy improved from 0.65517 to 0.89655, saving model to best_head_v3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7309 - loss: 0.8452 - val_accuracy: 0.8966 - val_loss: 0.3834 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8279 - loss: 0.5326\n",
      "Epoch 3: val_accuracy did not improve from 0.89655\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.8276 - loss: 0.5330 - val_accuracy: 0.8276 - val_loss: 0.3970 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8648 - loss: 0.4552\n",
      "Epoch 4: val_accuracy did not improve from 0.89655\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.8654 - loss: 0.4530 - val_accuracy: 0.8966 - val_loss: 0.3462 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9537 - loss: 0.2436\n",
      "Epoch 5: val_accuracy did not improve from 0.89655\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.9525 - loss: 0.2466 - val_accuracy: 0.8966 - val_loss: 0.3512 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6735 - loss: 0.9962\n",
      "Epoch 6: val_accuracy improved from -inf to 0.89655, saving model to best_finetune_v3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.6778 - loss: 0.9830 - val_accuracy: 0.8966 - val_loss: 0.2063 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8770 - loss: 0.4533\n",
      "Epoch 7: val_accuracy improved from 0.89655 to 0.93103, saving model to best_finetune_v3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.8765 - loss: 0.4537 - val_accuracy: 0.9310 - val_loss: 0.2263 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8639 - loss: 0.3795\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.93103\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8643 - loss: 0.3787 - val_accuracy: 0.8793 - val_loss: 0.2761 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9191 - loss: 0.3198\n",
      "Epoch 9: val_accuracy did not improve from 0.93103\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9183 - loss: 0.3225 - val_accuracy: 0.8793 - val_loss: 0.2366 - learning_rate: 5.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9386 - loss: 0.3302\n",
      "Epoch 10: val_accuracy improved from 0.93103 to 0.96552, saving model to best_finetune_v3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9371 - loss: 0.3307 - val_accuracy: 0.9655 - val_loss: 0.1636 - learning_rate: 5.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8647 - loss: 0.3765\n",
      "Epoch 11: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8663 - loss: 0.3734 - val_accuracy: 0.9138 - val_loss: 0.2054 - learning_rate: 5.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9151 - loss: 0.2930\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9162 - loss: 0.2889 - val_accuracy: 0.8966 - val_loss: 0.3330 - learning_rate: 5.0000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9135 - loss: 0.2375\n",
      "Epoch 13: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.9145 - loss: 0.2371 - val_accuracy: 0.8966 - val_loss: 0.3466 - learning_rate: 2.5000e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8618 - loss: 0.3756\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.8653 - loss: 0.3705 - val_accuracy: 0.8621 - val_loss: 0.3167 - learning_rate: 2.5000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8881 - loss: 0.3101\n",
      "Epoch 15: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8883 - loss: 0.3102 - val_accuracy: 0.9138 - val_loss: 0.2387 - learning_rate: 1.2500e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9486 - loss: 0.2113\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9485 - loss: 0.2119 - val_accuracy: 0.9138 - val_loss: 0.1864 - learning_rate: 1.2500e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9498 - loss: 0.2063\n",
      "Epoch 17: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.9498 - loss: 0.2062 - val_accuracy: 0.9138 - val_loss: 0.2515 - learning_rate: 6.2500e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9476 - loss: 0.2128\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.9463 - loss: 0.2157 - val_accuracy: 0.9310 - val_loss: 0.2967 - learning_rate: 6.2500e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9585 - loss: 0.2077\n",
      "Epoch 19: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.9573 - loss: 0.2106 - val_accuracy: 0.8966 - val_loss: 0.3235 - learning_rate: 3.1250e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9600 - loss: 0.2096\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.96552\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9601 - loss: 0.2090 - val_accuracy: 0.9483 - val_loss: 0.1963 - learning_rate: 3.1250e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\23hangin\\AppData\\Local\\Temp\\tmpsv56qe7i\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\23hangin\\AppData\\Local\\Temp\\tmpsv56qe7i\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\23hangin\\AppData\\Local\\Temp\\tmpsv56qe7i'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 120, 160, 3), dtype=tf.float32, name='keras_tensor_159')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 7), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1842887789264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887790992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887791376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887791184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887788880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887792528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887792912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887793296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887793104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887790416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887794448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887794832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887795216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887795024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887790608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887796368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887796752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887797136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887796944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887792144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887798288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887798672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887799056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887798864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887794064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887800208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887800592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887800976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887800784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887795984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887802128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887802704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887801360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887802512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842887799824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889736464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889737808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889738192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889738000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889736656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889739344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889739728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889740112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889739920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889737232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889741264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889741648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889742032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889741840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889737424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889743184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889743568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889743952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889743760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889738960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889745104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889745488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889745872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889745680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889740880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889747024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889747408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889747792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889747600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889742800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889748944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889749328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889749712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889749520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889744720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889750864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889751248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889751632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889751440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889746640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889750096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889245328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889244752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889752400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889748560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889246864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889247248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889247632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889247440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889244944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889248784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889249168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889249552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889249360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889245520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889250704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889251088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889251472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889251280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889246480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889252624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889253008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889253392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889253200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889248400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889254544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889254928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889255312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889255120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889250320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889256464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889245712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889257424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889257040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889252240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889258192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889258576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889258960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889258768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889257616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889260112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889259728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889259344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889260688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889256848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1842889257808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029853584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029853968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029853776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029852432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029855120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029855504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029855888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029855696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029852240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029857040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029857424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029857808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029857616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029853200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029858960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029859344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029859728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029859536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029854736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029860880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029861264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029861648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029861456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029856656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029862800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029863184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029863568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029863376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029858576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029864720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029865104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029865488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029865296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029860496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029866640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029867024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029867408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029867216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029862416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029864336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030245648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030246416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029866256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843029865872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030247376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030247760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030248144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030247952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030246608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030249296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030249680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030250064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030249872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030245456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030251216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030251600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030251984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030251792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030246992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030253136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030253520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030253904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030253712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030248912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030255056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030255440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030255824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030255632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030250832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030256976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030257360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030257744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030257552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030252752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030258896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030259280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030259664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030259472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030254672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030260816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030260432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030260048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030261392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030256592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030258512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030607248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030607632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030607440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030605904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030608784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030609168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030609552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030609360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030606672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030610704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030611088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030611472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030611280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030606288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030612624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030613008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030613392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030613200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030608400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030614544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030614928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030615312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030615120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030610320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030616464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030616848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030617232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030617040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030612240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030618384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030618768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030619152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030618960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030614160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030620304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030620688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030621072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030620880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030616080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030618000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030966736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030967312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030619920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030619536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030968272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030968656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030969040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030968848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030967504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030970192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030970576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030970960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030970768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030966544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030971344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030972496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030966352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030973648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030973072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843030974416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Saved FLOAT32 TFLite as 'road_classifier_v3.tflite'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ─── Config ────────────────────────────────────────────────────────────────\n",
    "INPUT_SIZE   = (120, 160)\n",
    "BATCH_SIZE   = 16\n",
    "NUM_CLASSES  = 7\n",
    "HEAD_EPOCHS  = 5\n",
    "FT_EPOCHS    = 15\n",
    "TOTAL_EPOCHS = HEAD_EPOCHS + FT_EPOCHS\n",
    "BASE_LR      = 1e-3\n",
    "FT_LR        = 1e-4\n",
    "DATA_DIR     = \"./data/preprocessedv3\"\n",
    "\n",
    "# ─── Data Generators ──────────────────────────────────────────────────────\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=4,\n",
    "    width_shift_range=0.08,\n",
    "    height_shift_range=0.08,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    DATA_DIR, target_size=INPUT_SIZE, batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', subset='training', shuffle=True\n",
    ")\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    DATA_DIR, target_size=INPUT_SIZE, batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', subset='validation', shuffle=False\n",
    ")\n",
    "\n",
    "# ─── Compute class weights (if imbalanced) ────────────────────────────────\n",
    "labels = train_gen.classes\n",
    "cw = compute_class_weight(class_weight='balanced',\n",
    "                          classes=np.unique(labels),\n",
    "                          y=labels)\n",
    "class_weights = dict(enumerate(cw))\n",
    "\n",
    "# ─── 1) Load MobileNetV2 backbone ──────────────────────────────────────────\n",
    "base = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    alpha=0.5,\n",
    "    input_shape=(*INPUT_SIZE, 3)\n",
    ")\n",
    "\n",
    "# ─── 2) Attach your custom head ────────────────────────────────────────────\n",
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(base.input, outputs)\n",
    "\n",
    "# ─── 3) Phase 1: Train only the head ───────────────────────────────────────\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=BASE_LR),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint('best_head_v3.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "]\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    epochs=HEAD_EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ─── 4) Phase 2: Unfreeze last 20 layers & fine-tune ──────────────────────\n",
    "for layer in base.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=FT_LR),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7, verbose=1),\n",
    "    ModelCheckpoint('best_finetune_v3.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "]\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    initial_epoch=HEAD_EPOCHS,\n",
    "    epochs=TOTAL_EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ─── 5) Save the final float32 Keras model ────────────────────────────────\n",
    "model.save('road_classifier_v3.h5')\n",
    "\n",
    "# ─── 6) Convert to FLOAT32 TFLite (no quantization ops) ──────────────────\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# **Do not** set optimizations or integer types\n",
    "tflite_model = converter.convert()\n",
    "with open('road_classifier_v3.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Saved FLOAT32 TFLite as 'road_classifier_v3.tflite'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import MobileNetV2\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Configure constants\n",
    "# INPUT_SIZE_X = 120\n",
    "# INPUT_SIZE_Y = 160\n",
    "# BATCH_SIZE = 16\n",
    "# NUM_CLASSES = 7\n",
    "# EPOCHS = 20\n",
    "\n",
    "# # Load base model with reduced size\n",
    "# base_model = MobileNetV2(\n",
    "#     weights='imagenet',\n",
    "#     include_top=False,\n",
    "#     input_shape=(INPUT_SIZE_Y, INPUT_SIZE_X, 3),\n",
    "#     alpha=0.35\n",
    "# )\n",
    "\n",
    "# # Add custom head with fewer parameters\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(64, activation='relu')(x)  # Further reduced from 64\n",
    "# predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # Freeze base layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # Data generators with smaller image size\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     zoom_range=0.2,\n",
    "#     validation_split=0.2  # Create validation split from training data\n",
    "# )\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     './data/preprocessedv3',\n",
    "#     target_size=(INPUT_SIZE_Y, INPUT_SIZE_X),\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     class_mode='categorical',\n",
    "#     shuffle=True,\n",
    "#     subset='training'  # Set as training data\n",
    "# )\n",
    "\n",
    "# validation_generator = train_datagen.flow_from_directory(\n",
    "#     './data/preprocessedv3',\n",
    "#     target_size=(INPUT_SIZE_Y, INPUT_SIZE_X),\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     class_mode='categorical',\n",
    "#     shuffle=False,\n",
    "#     subset='validation'  # Set as validation data\n",
    "# )\n",
    "\n",
    "# # Compile & fit\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=EPOCHS,\n",
    "#     validation_data=validation_generator\n",
    "# )\n",
    "\n",
    "# # Plot training history\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "# plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "# plt.title('Accuracy vs. Epoch')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "# plt.title('Loss vs. Epoch')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Save Keras model\n",
    "# # model.save('road_classifier_keras.h5')\n",
    "# # print(\"Keras model saved as road_classifier_keras.h5\")\n",
    "\n",
    "# # Create TFLite converter WITHOUT quantization settings\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# # No optimizations or quantization parameters\n",
    "# # This will produce a standard float32 model without QUANTIZE/DEQUANTIZE ops\n",
    "\n",
    "# # Convert model to TFLite\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save TFLite model\n",
    "# with open('road_classifier_v3.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)\n",
    "# print(\"Float32 model saved as road_classifier_v3.tflite\")\n",
    "\n",
    "# print(\"\\nNow convert to kmodel using:\")\n",
    "# print(\"ncc compile road_classifier_v3.tflite road_classifier.kmodel -i tflite -o kmodel -t k210 --dataset ./data/preprocessedv2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88cc89",
   "metadata": {},
   "source": [
    "### **Get the correct order of labels for the maix end**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdae24cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'forward': 0, 'intersection': 1, 'left_right_t': 2, 'left_turn': 3, 'right_turn': 4, 'straight_left': 5, 'straight_right': 6}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4069cea",
   "metadata": {},
   "source": [
    "### **Small test with non-training images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b7003b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Predicted road type: intersection\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = './data/testing/intersection-test.jpg'\n",
    "\n",
    "#input_size = 224\n",
    "input_size = 128\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(img_path, target_size=(input_size, input_size))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array = img_array / 255.0  # Normalize to match training preprocessing\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get class indices to map predictions back to labels\n",
    "class_indices = train_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_indices.items()}  # Invert mapping\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "predicted_label = class_labels[predicted_class_index]\n",
    "\n",
    "print(f\"Predicted road type: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3de64",
   "metadata": {},
   "source": [
    "### **Validate that the model is ready for conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca2333e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ops used in v2:\n",
      "  • CONV_2D\n",
      "  • DEPTHWISE_CONV_2D\n",
      "  • ADD\n",
      "  • MEAN\n",
      "  • FULLY_CONNECTED\n",
      "  • SOFTMAX\n",
      "Ops used v3:\n",
      "  • CONV_2D\n",
      "  • DEPTHWISE_CONV_2D\n",
      "  • ADD\n",
      "  • MEAN\n",
      "  • FULLY_CONNECTED\n",
      "  • SOFTMAX\n"
     ]
    }
   ],
   "source": [
    "import flatbuffers\n",
    "from tflite.Model import Model\n",
    "import tflite.BuiltinOperator as BuiltinOp\n",
    "\n",
    "# Build a mapping from code→name\n",
    "op_names_1 = {\n",
    "    val: name\n",
    "    for name, val in BuiltinOp.__dict__.items()\n",
    "    if isinstance(val, int)\n",
    "}\n",
    "\n",
    "# Load your TFLite flatbuffer\n",
    "with open(\"road_classifier_v2.tflite\", \"rb\") as f:\n",
    "    buf = f.read()\n",
    "\n",
    "model = Model.GetRootAsModel(buf, 0)\n",
    "\n",
    "print(\"Ops used in v2:\")\n",
    "seen = set()\n",
    "for i in range(model.OperatorCodesLength()):\n",
    "    code = model.OperatorCodes(i).BuiltinCode()\n",
    "    name = op_names_1.get(code, f\"UNKNOWN({code})\")\n",
    "    if name not in seen:\n",
    "        print(f\"  • {name}\")\n",
    "        seen.add(name)\n",
    "\n",
    "op_names_2 = {\n",
    "    val: name\n",
    "    for name, val in BuiltinOp.__dict__.items()\n",
    "    if isinstance(val, int)\n",
    "}\n",
    "\n",
    "with open (\"road_classifier_v3.tflite\", \"rb\") as f:\n",
    "    buf = f.read()\n",
    "\n",
    "model = Model.GetRootAsModel(buf, 0)\n",
    "\n",
    "print(\"Ops used v3:\")\n",
    "seen = set()\n",
    "for i in range(model.OperatorCodesLength()):\n",
    "    code = model.OperatorCodes(i).BuiltinCode()\n",
    "    name = op_names_2.get(code, f\"UNKNOWN({code})\")\n",
    "    if name not in seen:\n",
    "        print(f\"  • {name}\")\n",
    "        seen.add(name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
